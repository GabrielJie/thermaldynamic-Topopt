
# Potential optimizations:

    - in the first iteration, since all elemental stiffness matrices are the same, use this one single one to assemble the global grid
        - while assembly and the first iteration is done, concurrently copy the remaining element stiffness matrices, so that by the time the first iteration is done, each of these local stiffness matrices can be updated with its density variable

    - assembleGrid_GPU in assemble.cu
        - now you are doing a for loop for each thread id, meaning, one thread handles one row, which scans through the columns
        - you wanted to try and have each thread handles ONE matrix cell, you're stuck here
            - this is a potential optimization
        - some refresher :

            setAt( 2*node_index[i], 2*node_index[j], g_value, g_index, g_max_row_size, valueAt( 2*i, 2*j, l_value, l_index, l_max_row_size) );
                    |
                    -> here, i is the row of the global matrix.
                        - in this for loop, j is increased because we're scanning along the columns. i remains static
                
            NOTE: the for loop runs two functions:

                    setAt( 2*node_index[i], 2*node_index[j], g_value, g_index, g_max_row_size, valueAt( 2*i, 2*j, l_value, l_index, l_max_row_size) );
                    setAt( 2*node_index[i], 2*node_index[j] + 1 , g_value, g_index, g_max_row_size, valueAt( 2*i, 2*j + 1 , l_value, l_index, l_max_row_size) );
        - NOTE: look into running the kernels in a 2D grid


    - while assembling in CPU, have GPU malloc and memcpy stuff, like residuum and displacement vectors, gmg multilevel matrices,


TODO: read these:
    https://devblogs.nvidia.com/how-overlap-data-transfers-cuda-cc/
    https://devblogs.nvidia.com/faster-parallel-reductions-kepler/
    https://devblogs.nvidia.com/finite-difference-methods-cuda-cc-part-1/   (from prof)





# Issues:



TODO:       norm() add tree-like when adding the first threads of each block

TODO:       idea of optimization:
                - while foo is copied back and forth to host, do an async memcpy and continue with calculation
                    - doesn't matter if it's wasteful, can just quit if it has converged

            

CHECK:      When calculating the max_row_size on the device, we have to copy result back to CPU so that CPU will cudamalloc and cpy the required size for the vectors value and index
                - maybe not worthwhile to have it on the GPU?


TODO:       boundary condition (identity row)



TODO:       repair some reduction functions, add this in the beginning:

            __global__ 
            void sumOfVector_GPU(double* sum, double* x, size_t n)
            {
                int id = blockDim.x * blockIdx.x + threadIdx.x;
                int stride = blockDim.x*gridDim.x;
                
                __shared__ double cache[1024];
                cache[threadIdx.x] = 0;    < --- NOTE:
                
                double temp = 0.0;
                while(id < n)
                {
                    temp += x[id];


TODO:       repair PSFEM's calculateDimensions

            __host__ 
            void calculateDimensions(size_t N, dim3 &blockDim, dim3 &gridDim)
            {
                if ( N <= 1024 )
                {
                    blockDim.x = 1024; blockDim.y = 1; blockDim.z = 1; //NOTE: here, change N -> 1024, so that reductions work
                    gridDim.x  = 1; gridDim.y = 1; gridDim.z = 1;
                }

            .. because reduction kernels need full blocks to work